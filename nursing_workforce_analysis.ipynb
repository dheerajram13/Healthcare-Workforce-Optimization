{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare Workforce Optimization: Nursing Demand Prediction\n",
    "\n",
    "## Project Overview\n",
    "**Objective**: Develop a robust ML model to predict nursing workforce requirements for Q1 2024 based on 2023 historical data.\n",
    "\n",
    "**Business Impact**:\n",
    "- Optimize staffing levels across 5 hospital wards\n",
    "- Reduce overtime costs and critical staffing incidents\n",
    "- Improve patient care through adequate nurse-to-patient ratios\n",
    "\n",
    "**Methodology**:\n",
    "- Time-series aware ML with proper train/validation splits\n",
    "- Seasonal pattern recognition (Q1 validation for Q1 prediction)\n",
    "- Comprehensive feature engineering (100+ features)\n",
    "- Uncertainty quantification with 99% confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration\n",
    "class Config:\n",
    "    \"\"\"Central configuration for the project\"\"\"\n",
    "    \n",
    "    # Data paths\n",
    "    DATA_PATH = 'AO8_Stage 3_At home.csv'\n",
    "    MODEL_DIR = 'models'\n",
    "    OUTPUT_DIR = 'outputs'\n",
    "    \n",
    "    # Model parameters\n",
    "    RANDOM_STATE = 42\n",
    "    TEST_SIZE_DAYS = 90  # Q1 validation period\n",
    "    \n",
    "    # Feature engineering\n",
    "    LAG_PERIODS = [1, 7, 14]\n",
    "    ROLLING_WINDOWS = [3, 7, 14, 30]\n",
    "    \n",
    "    # Business rules\n",
    "    HOURLY_NURSE_COST = 50  # USD per hour\n",
    "    SHIFT_HOURS = 8\n",
    "    QUARTER_DAYS = 90\n",
    "    \n",
    "    # Model hyperparameters (will be tuned)\n",
    "    RF_PARAMS = {\n",
    "        'n_estimators': [200, 250, 300],\n",
    "        'max_depth': [10, 12, 15],\n",
    "        'min_samples_split': [5, 8, 10],\n",
    "        'min_samples_leaf': [2, 4, 6],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def create_directories(cls):\n",
    "        \"\"\"Create necessary directories if they don't exist\"\"\"\n",
    "        os.makedirs(cls.MODEL_DIR, exist_ok=True)\n",
    "        os.makedirs(cls.OUTPUT_DIR, exist_ok=True)\n",
    "        logger.info(f\"Directories created: {cls.MODEL_DIR}, {cls.OUTPUT_DIR}\")\n",
    "\n",
    "# Initialize directories\n",
    "Config.create_directories()\n",
    "logger.info(\"Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_validate_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load dataset with comprehensive validation.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to CSV file\n",
    "        \n",
    "    Returns:\n",
    "        Validated DataFrame\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If file doesn't exist\n",
    "        ValueError: If data validation fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv(filepath)\n",
    "        logger.info(f\"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        \n",
    "        # Expected columns\n",
    "        expected_columns = [\n",
    "            'date', 'ward', 'nurses_scheduled', 'nurses_on_shift',\n",
    "            'patients_admitted', 'bed_occupancy_rate', 'sick_leave',\n",
    "            'overtime_hours', 'shift_type'\n",
    "        ]\n",
    "        \n",
    "        # Validate columns\n",
    "        missing_cols = set(expected_columns) - set(df.columns)\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "        \n",
    "        # Convert date\n",
    "        df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "        \n",
    "        # Validate data quality\n",
    "        null_counts = df.isnull().sum()\n",
    "        if null_counts.any():\n",
    "            logger.warning(f\"Null values found:\\n{null_counts[null_counts > 0]}\")\n",
    "        \n",
    "        # Validate numeric ranges\n",
    "        assert (df['nurses_scheduled'] >= 0).all(), \"Negative scheduled nurses\"\n",
    "        assert (df['nurses_on_shift'] >= 0).all(), \"Negative on-shift nurses\"\n",
    "        assert (df['bed_occupancy_rate'] >= 0).all() and (df['bed_occupancy_rate'] <= 100).all(), \\\n",
    "            \"Invalid bed occupancy rate\"\n",
    "        \n",
    "        # Validate categorical values\n",
    "        valid_wards = ['ICU', 'Emergency', 'Pediatrics', 'General Surgery', 'Maternity']\n",
    "        assert set(df['ward'].unique()).issubset(valid_wards), \"Invalid ward names\"\n",
    "        \n",
    "        valid_shifts = ['Day', 'Night']\n",
    "        assert set(df['shift_type'].unique()).issubset(valid_shifts), \"Invalid shift types\"\n",
    "        \n",
    "        logger.info(\"Data validation passed\")\n",
    "        logger.info(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "        logger.info(f\"Wards: {sorted(df['ward'].unique())}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {filepath}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Data loading failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load data\n",
    "df_raw = load_and_validate_data(Config.DATA_PATH)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create basic temporal and business features.\n",
    "    \n",
    "    Args:\n",
    "        df: Raw DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with basic features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Temporal features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    df['is_weekend'] = (df['date'].dt.dayofweek >= 5).astype(int)\n",
    "    \n",
    "    # Business metrics\n",
    "    df['staffing_shortfall'] = df['nurses_scheduled'] - df['nurses_on_shift']\n",
    "    df['staffing_ratio'] = df['nurses_on_shift'] / df['nurses_scheduled'].replace(0, 1)\n",
    "    df['patients_per_nurse'] = df['patients_admitted'] / df['nurses_on_shift'].replace(0, 1)\n",
    "    df['overtime_per_nurse'] = df['overtime_hours'] / df['nurses_on_shift'].replace(0, 1)\n",
    "    df['sick_leave_rate'] = df['sick_leave'] / df['nurses_scheduled'].replace(0, 1)\n",
    "    \n",
    "    # Sort by ward and date for proper time series handling\n",
    "    df = df.sort_values(['ward', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    logger.info(f\"Basic features created. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Create basic features\n",
    "df = create_basic_features(df_raw)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== DATASET SUMMARY ===\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"Days covered: {(df['date'].max() - df['date'].min()).days + 1}\")\n",
    "print(f\"Wards: {len(df['ward'].unique())}\")\n",
    "print(f\"Records per ward: {len(df) / len(df['ward'].unique()):.0f}\")\n",
    "\n",
    "print(\"\\n=== KEY METRICS ===\")\n",
    "print(f\"Average scheduled nurses: {df['nurses_scheduled'].mean():.2f}\")\n",
    "print(f\"Average nurses on shift: {df['nurses_on_shift'].mean():.2f}\")\n",
    "print(f\"Average staffing shortfall: {df['staffing_shortfall'].mean():.2f}\")\n",
    "print(f\"Average staffing ratio: {df['staffing_ratio'].mean():.2%}\")\n",
    "print(f\"Shifts with shortfall: {(df['staffing_shortfall'] > 0).mean():.2%}\")\n",
    "print(f\"Critical understaffing (≥5 nurses): {(df['staffing_shortfall'] >= 5).mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Staffing trends by quarter\n",
    "quarterly_stats = df.groupby('quarter').agg({\n",
    "    'nurses_on_shift': 'mean',\n",
    "    'staffing_shortfall': 'mean',\n",
    "    'overtime_hours': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(quarterly_stats['quarter'], quarterly_stats['staffing_shortfall'], \n",
    "        color='coral', alpha=0.7, label='Avg Shortfall')\n",
    "ax1.set_xlabel('Quarter')\n",
    "ax1.set_ylabel('Average Staffing Shortfall (nurses)', color='coral')\n",
    "ax1.tick_params(axis='y', labelcolor='coral')\n",
    "ax1.set_title('Quarterly Staffing Patterns', fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.plot(quarterly_stats['quarter'], quarterly_stats['nurses_on_shift'], \n",
    "              marker='o', color='steelblue', linewidth=2, label='Avg Nurses')\n",
    "ax1_twin.set_ylabel('Average Nurses on Shift', color='steelblue')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='steelblue')\n",
    "\n",
    "# 2. Ward performance comparison\n",
    "ward_stats = df.groupby('ward').agg({\n",
    "    'staffing_shortfall': 'mean',\n",
    "    'staffing_ratio': 'mean'\n",
    "}).sort_values('staffing_shortfall', ascending=False)\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "ward_stats['staffing_shortfall'].plot(kind='barh', ax=ax2, color='crimson', alpha=0.7)\n",
    "ax2.set_xlabel('Average Staffing Shortfall (nurses)')\n",
    "ax2.set_ylabel('Ward')\n",
    "ax2.set_title('Ward Performance: Staffing Shortfall', fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Monthly patterns\n",
    "monthly_stats = df.groupby('month').agg({\n",
    "    'staffing_shortfall': 'mean',\n",
    "    'overtime_hours': 'mean'\n",
    "})\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(monthly_stats.index, monthly_stats['staffing_shortfall'], \n",
    "         marker='o', linewidth=2, color='darkred', label='Avg Shortfall')\n",
    "ax3.axhline(y=monthly_stats['staffing_shortfall'].mean(), \n",
    "            color='red', linestyle='--', alpha=0.5, label='Annual Average')\n",
    "ax3.set_xlabel('Month')\n",
    "ax3.set_ylabel('Average Staffing Shortfall (nurses)')\n",
    "ax3.set_title('Monthly Staffing Shortfall Patterns', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Shift type comparison\n",
    "shift_stats = df.groupby('shift_type').agg({\n",
    "    'nurses_on_shift': 'mean',\n",
    "    'staffing_shortfall': 'mean',\n",
    "    'overtime_hours': 'mean'\n",
    "})\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "x = np.arange(len(shift_stats.index))\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, shift_stats['nurses_on_shift'], width, \n",
    "        label='Nurses on Shift', color='steelblue', alpha=0.7)\n",
    "ax4.bar(x + width/2, shift_stats['staffing_shortfall'], width, \n",
    "        label='Shortfall', color='coral', alpha=0.7)\n",
    "ax4.set_xlabel('Shift Type')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.set_title('Shift Type Comparison', fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(shift_stats.index)\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Config.OUTPUT_DIR}/eda_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"EDA visualizations saved to {Config.OUTPUT_DIR}/eda_overview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    \"\"\"\n",
    "    Feature engineering pipeline for nursing workforce data.\n",
    "    \n",
    "    Implements time-series aware feature creation without data leakage.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.feature_names = []\n",
    "        \n",
    "    def create_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create comprehensive temporal features.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        logger.info(\"Creating temporal features...\")\n",
    "        \n",
    "        # Cyclical encoding for temporal features\n",
    "        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "        df['week_sin'] = np.sin(2 * np.pi * df['week_of_year'] / 52)\n",
    "        df['week_cos'] = np.cos(2 * np.pi * df['week_of_year'] / 52)\n",
    "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "        \n",
    "        # Day of week indicators\n",
    "        df['is_monday'] = (df['day_of_week'] == 0).astype(int)\n",
    "        df['is_friday'] = (df['day_of_week'] == 4).astype(int)\n",
    "        \n",
    "        # Seasonal patterns (from EDA)\n",
    "        df['is_q1'] = (df['quarter'] == 1).astype(int)\n",
    "        df['is_feb'] = (df['month'] == 2).astype(int)  # Worst month\n",
    "        df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_workload_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create workload and intensity features.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        logger.info(\"Creating workload features...\")\n",
    "        \n",
    "        # Intensity indicators\n",
    "        df['high_occupancy'] = (df['bed_occupancy_rate'] > 85).astype(int)\n",
    "        df['critical_occupancy'] = (df['bed_occupancy_rate'] > 95).astype(int)\n",
    "        df['high_overtime'] = (df['overtime_hours'] > df['overtime_hours'].quantile(0.75)).astype(int)\n",
    "        df['multiple_sick'] = (df['sick_leave'] > 2).astype(int)\n",
    "        \n",
    "        # Understaffing levels\n",
    "        df['is_understaffed'] = (df['staffing_shortfall'] > 0).astype(int)\n",
    "        df['severe_understaffing'] = (df['staffing_shortfall'] >= 3).astype(int)\n",
    "        df['critical_understaffing'] = (df['staffing_shortfall'] >= 5).astype(int)\n",
    "        \n",
    "        # Combined stress indicators\n",
    "        df['weekend_understaffed'] = (df['is_weekend'] & df['is_understaffed']).astype(int)\n",
    "        df['high_stress'] = ((df['high_occupancy']) & (df['is_understaffed'])).astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_lag_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create lag features without data leakage.\n",
    "        \n",
    "        IMPORTANT: All lags use only historical data (shift to avoid leakage).\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        logger.info(\"Creating lag features...\")\n",
    "        \n",
    "        # Variables to create lags for\n",
    "        lag_vars = [\n",
    "            'nurses_on_shift', 'staffing_shortfall', 'overtime_hours',\n",
    "            'sick_leave', 'patients_admitted', 'bed_occupancy_rate'\n",
    "        ]\n",
    "        \n",
    "        for var in lag_vars:\n",
    "            # Point-in-time lags\n",
    "            for lag in self.config.LAG_PERIODS:\n",
    "                df[f'{var}_lag{lag}'] = df.groupby('ward')[var].shift(lag)\n",
    "            \n",
    "            # Rolling averages (shifted to avoid leakage)\n",
    "            for window in self.config.ROLLING_WINDOWS:\n",
    "                df[f'{var}_avg{window}d'] = (\n",
    "                    df.groupby('ward')[var]\n",
    "                    .rolling(window=window, min_periods=1)\n",
    "                    .mean()\n",
    "                    .shift(1)  # Shift to avoid leakage\n",
    "                    .reset_index(0, drop=True)\n",
    "                )\n",
    "        \n",
    "        # Trend indicators\n",
    "        for var in ['nurses_on_shift', 'staffing_shortfall']:\n",
    "            df[f'{var}_trend'] = df[var] - df[f'{var}_lag7']\n",
    "            df[f'{var}_increasing'] = (df[f'{var}_trend'] > 0).astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_categorical_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Encode categorical variables.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        logger.info(\"Encoding categorical features...\")\n",
    "        \n",
    "        # One-hot encode ward and shift type\n",
    "        ward_dummies = pd.get_dummies(df['ward'], prefix='ward', drop_first=False)\n",
    "        shift_dummies = pd.get_dummies(df['shift_type'], prefix='shift', drop_first=False)\n",
    "        \n",
    "        df = pd.concat([df, ward_dummies, shift_dummies], axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply all feature engineering steps.\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting feature engineering pipeline...\")\n",
    "        \n",
    "        df = self.create_temporal_features(df)\n",
    "        df = self.create_workload_features(df)\n",
    "        df = self.create_categorical_features(df)\n",
    "        df = self.create_lag_features(df)\n",
    "        \n",
    "        # Fill missing values from lag features\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            if df[col].isnull().any():\n",
    "                # Forward fill within ward, then use median\n",
    "                df[col] = df.groupby('ward')[col].fillna(method='ffill')\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "        logger.info(f\"Feature engineering complete. Final shape: {df.shape}\")\n",
    "        return df\n",
    "\n",
    "# Apply feature engineering\n",
    "feature_engineer = FeatureEngineer(Config)\n",
    "df_features = feature_engineer.fit_transform(df)\n",
    "\n",
    "print(f\"\\nFeatures created: {df_features.shape[1]} columns\")\n",
    "print(f\"Original columns: {df.shape[1]}\")\n",
    "print(f\"New features: {df_features.shape[1] - df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train/Validation Split (Time-Series Aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seasonal_split(df: pd.DataFrame, config: Config):\n",
    "    \"\"\"\n",
    "    Create seasonally-aware train/validation split.\n",
    "    \n",
    "    Strategy:\n",
    "    - Training: Apr-Dec 2023 (Q2, Q3, Q4)\n",
    "    - Validation: Q1 2023 (Jan-Mar) - same season as Q1 2024 prediction target\n",
    "    \n",
    "    This ensures validation performance reflects expected Q1 2024 accuracy.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with features\n",
    "        config: Configuration object\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_df, val_df, feature_cols, target_col)\n",
    "    \"\"\"\n",
    "    logger.info(\"Creating seasonal train/validation split...\")\n",
    "    \n",
    "    # Define Q1 validation period (same season as prediction target)\n",
    "    q1_start = pd.Timestamp('2023-01-01')\n",
    "    q1_end = pd.Timestamp('2023-03-31')\n",
    "    train_start = pd.Timestamp('2023-04-01')\n",
    "    train_end = pd.Timestamp('2023-12-31')\n",
    "    \n",
    "    # Create masks\n",
    "    val_mask = (df['date'] >= q1_start) & (df['date'] <= q1_end)\n",
    "    train_mask = (df['date'] >= train_start) & (df['date'] <= train_end)\n",
    "    \n",
    "    df_train = df[train_mask].copy()\n",
    "    df_val = df[val_mask].copy()\n",
    "    \n",
    "    logger.info(f\"Training period: {df_train['date'].min().date()} to {df_train['date'].max().date()}\")\n",
    "    logger.info(f\"Validation period: {df_val['date'].min().date()} to {df_val['date'].max().date()}\")\n",
    "    logger.info(f\"Training samples: {len(df_train):,}\")\n",
    "    logger.info(f\"Validation samples: {len(df_val):,}\")\n",
    "    \n",
    "    # Define target and features\n",
    "    target_col = 'nurses_on_shift'\n",
    "    \n",
    "    # Exclude columns that should not be features\n",
    "    exclude_cols = [\n",
    "        'date', 'ward', 'shift_type',  # Non-numeric identifiers\n",
    "        target_col,  # Target variable\n",
    "        'nurses_scheduled',  # Too closely related to target\n",
    "        'year', 'day_of_week'  # Redundant with encoded versions\n",
    "    ]\n",
    "    \n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    logger.info(f\"Feature columns: {len(feature_cols)}\")\n",
    "    \n",
    "    # Verify no data leakage\n",
    "    assert df_train['date'].max() < df_val['date'].min() or df_val['date'].max() < df_train['date'].min(), \\\n",
    "        \"ERROR: Temporal overlap between train and validation sets!\"\n",
    "    \n",
    "    logger.info(\"Seasonal split created successfully (no data leakage)\")\n",
    "    \n",
    "    return df_train, df_val, feature_cols, target_col\n",
    "\n",
    "# Create split\n",
    "df_train, df_val, feature_cols, target_col = create_seasonal_split(df_features, Config)\n",
    "\n",
    "# Prepare X and y\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[target_col]\n",
    "X_val = df_val[feature_cols]\n",
    "y_val = df_val[target_col]\n",
    "\n",
    "print(f\"\\n=== MODELING DATA ===\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"Target: {target_col}\")\n",
    "print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_tuning(X_train, y_train, config: Config):\n",
    "    \"\"\"\n",
    "    Train Random Forest with hyperparameter tuning using TimeSeriesSplit.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        config: Configuration object\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best_model, cv_results)\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting hyperparameter tuning...\")\n",
    "    \n",
    "    # Time series cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # Initialize base model\n",
    "    rf = RandomForestRegressor(\n",
    "        random_state=config.RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        oob_score=True\n",
    "    )\n",
    "    \n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=config.RF_PARAMS,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    logger.info(\"Running grid search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    logger.info(\"Hyperparameter tuning complete\")\n",
    "    logger.info(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    logger.info(f\"Best CV MAE: {-grid_search.best_score_:.3f}\")\n",
    "    logger.info(f\"OOB Score: {best_model.oob_score_:.3f}\")\n",
    "    \n",
    "    return best_model, grid_search.cv_results_\n",
    "\n",
    "# Train model\n",
    "model, cv_results = train_model_with_tuning(X_train, y_train, Config)\n",
    "\n",
    "# Save model\n",
    "model_path = f\"{Config.MODEL_DIR}/nursing_workforce_model.joblib\"\n",
    "joblib.dump(model, model_path)\n",
    "logger.info(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_train, y_train: Training data\n",
    "        X_val, y_val: Validation data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    logger.info(\"Evaluating model performance...\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Training metrics\n",
    "    train_metrics = {\n",
    "        'mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'r2': r2_score(y_train, y_train_pred),\n",
    "        'mape': mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "    }\n",
    "    \n",
    "    # Validation metrics\n",
    "    val_metrics = {\n",
    "        'mae': mean_absolute_error(y_val, y_val_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_val, y_val_pred)),\n",
    "        'r2': r2_score(y_val, y_val_pred),\n",
    "        'mape': mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nTRAINING SET:\")\n",
    "    print(f\"  MAE:  {train_metrics['mae']:.3f} nurses\")\n",
    "    print(f\"  RMSE: {train_metrics['rmse']:.3f} nurses\")\n",
    "    print(f\"  R²:   {train_metrics['r2']:.3f} ({train_metrics['r2']*100:.1f}% variance explained)\")\n",
    "    print(f\"  MAPE: {train_metrics['mape']:.3%}\")\n",
    "    \n",
    "    print(\"\\nVALIDATION SET (Q1 2023 - Seasonal Benchmark):\")\n",
    "    print(f\"  MAE:  {val_metrics['mae']:.3f} nurses\")\n",
    "    print(f\"  RMSE: {val_metrics['rmse']:.3f} nurses\")\n",
    "    print(f\"  R²:   {val_metrics['r2']:.3f} ({val_metrics['r2']*100:.1f}% variance explained)\")\n",
    "    print(f\"  MAPE: {val_metrics['mape']:.3%}\")\n",
    "    \n",
    "    # Overfitting check\n",
    "    overfit_diff = train_metrics['mae'] - val_metrics['mae']\n",
    "    print(f\"\\nOVERFITTING CHECK:\")\n",
    "    print(f\"  MAE difference: {overfit_diff:.3f} nurses\")\n",
    "    if abs(overfit_diff) < 0.5:\n",
    "        print(f\"  Status: EXCELLENT (minimal overfitting)\")\n",
    "    elif abs(overfit_diff) < 1.0:\n",
    "        print(f\"  Status: GOOD (acceptable generalization)\")\n",
    "    else:\n",
    "        print(f\"  Status: WARNING (check for overfitting)\")\n",
    "    \n",
    "    print(\"\\nOOB Score: {:.3f}\".format(model.oob_score_))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return {\n",
    "        'train': train_metrics,\n",
    "        'val': val_metrics,\n",
    "        'predictions': {'train': y_train_pred, 'val': y_val_pred}\n",
    "    }\n",
    "\n",
    "# Evaluate\n",
    "results = evaluate_model(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 20 MOST IMPORTANT FEATURES ===\")\n",
    "for idx, row in feature_importance.head(20).iterrows():\n",
    "    print(f\"{row['importance']:>6.3f}  {row['feature']}\")\n",
    "\n",
    "# Visualize top features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='steelblue', alpha=0.7)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 15 Most Important Features', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Config.OUTPUT_DIR}/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"Feature importance saved to {Config.OUTPUT_DIR}/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Validation predictions\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_val, results['predictions']['val'], alpha=0.5, s=30, color='steelblue')\n",
    "perfect_line = np.linspace(y_val.min(), y_val.max(), 100)\n",
    "ax1.plot(perfect_line, perfect_line, 'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax1.set_xlabel('Actual Nurses on Shift', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Predicted Nurses on Shift', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'Validation Predictions (Q1 2023)\\nMAE: {results[\"val\"][\"mae\"]:.3f}, R²: {results[\"val\"][\"r2\"]:.3f}', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "ax2 = axes[1]\n",
    "residuals = y_val - results['predictions']['val']\n",
    "ax2.scatter(results['predictions']['val'], residuals, alpha=0.5, s=30, color='coral')\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.axhline(y=results['val']['mae'], color='orange', linestyle=':', linewidth=1, label=f'+/- MAE ({results[\"val\"][\"mae\"]:.2f})')\n",
    "ax2.axhline(y=-results['val']['mae'], color='orange', linestyle=':', linewidth=1)\n",
    "ax2.set_xlabel('Predicted Nurses on Shift', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Residuals (Actual - Predicted)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Residual Plot (Q1 2023 Validation)', fontsize=13, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Config.OUTPUT_DIR}/prediction_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"Prediction analysis saved to {Config.OUTPUT_DIR}/prediction_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Q1 2024 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q1_2024_predictions(model, df_val, feature_cols, config: Config):\n",
    "    \"\"\"\n",
    "    Generate Q1 2024 staffing predictions with uncertainty quantification.\n",
    "    \n",
    "    Uses Q1 2023 validation data as baseline for Q1 2024 seasonal patterns.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        df_val: Q1 2023 validation data (same season as prediction target)\n",
    "        feature_cols: List of feature columns\n",
    "        config: Configuration object\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with ward-level predictions and uncertainty\n",
    "    \"\"\"\n",
    "    logger.info(\"Generating Q1 2024 predictions...\")\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for ward in df_val['ward'].unique():\n",
    "        # Get Q1 2023 data for this ward\n",
    "        ward_data = df_val[df_val['ward'] == ward].copy()\n",
    "        \n",
    "        if len(ward_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Current Q1 baseline\n",
    "        q1_2023_avg = ward_data['nurses_on_shift'].mean()\n",
    "        \n",
    "        # Predict using Q1 patterns\n",
    "        X_ward = ward_data[feature_cols]\n",
    "        ward_predictions = model.predict(X_ward)\n",
    "        \n",
    "        # Statistics\n",
    "        predicted_avg = ward_predictions.mean()\n",
    "        prediction_std = ward_predictions.std()\n",
    "        \n",
    "        # Uncertainty components\n",
    "        model_uncertainty = results['val']['rmse']  # From validation\n",
    "        seasonal_uncertainty = prediction_std if prediction_std > 0 else 0.5\n",
    "        forecast_uncertainty = 0.8  # Future unknown factors\n",
    "        \n",
    "        total_uncertainty = np.sqrt(\n",
    "            model_uncertainty**2 + \n",
    "            seasonal_uncertainty**2 + \n",
    "            forecast_uncertainty**2\n",
    "        )\n",
    "        \n",
    "        # 99% confidence interval (2.58 std for 99%)\n",
    "        ci_lower = predicted_avg - 2.58 * total_uncertainty\n",
    "        ci_upper = predicted_avg + 2.58 * total_uncertainty\n",
    "        \n",
    "        # Calculate change\n",
    "        change = predicted_avg - q1_2023_avg\n",
    "        change_pct = (change / q1_2023_avg) * 100\n",
    "        \n",
    "        # Action recommendation\n",
    "        if abs(change) >= 2.0:\n",
    "            action = \"URGENT INCREASE\" if change > 0 else \"MAJOR REDUCTION\"\n",
    "            priority = \"HIGH\"\n",
    "        elif abs(change) >= 1.0:\n",
    "            action = \"INCREASE\" if change > 0 else \"DECREASE\"\n",
    "            priority = \"MEDIUM\"\n",
    "        elif abs(change) >= 0.5:\n",
    "            action = \"MONITOR\"\n",
    "            priority = \"LOW\"\n",
    "        else:\n",
    "            action = \"MAINTAIN\"\n",
    "            priority = \"LOW\"\n",
    "        \n",
    "        predictions.append({\n",
    "            'ward': ward,\n",
    "            'q1_2023_baseline': q1_2023_avg,\n",
    "            'q1_2024_predicted': predicted_avg,\n",
    "            'change': change,\n",
    "            'change_pct': change_pct,\n",
    "            'uncertainty': total_uncertainty,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'action': action,\n",
    "            'priority': priority\n",
    "        })\n",
    "    \n",
    "    df_predictions = pd.DataFrame(predictions)\n",
    "    df_predictions = df_predictions.sort_values('change', ascending=False)\n",
    "    \n",
    "    logger.info(f\"Q1 2024 predictions generated for {len(df_predictions)} wards\")\n",
    "    \n",
    "    return df_predictions\n",
    "\n",
    "# Generate predictions\n",
    "q1_2024_predictions = generate_q1_2024_predictions(model, df_val, feature_cols, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Q1 2024 predictions\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\" \"*30 + \"Q1 2024 NURSING WORKFORCE PREDICTIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\nMETHODOLOGY:\")\n",
    "print(\"  • Training: Apr-Dec 2023 (Q2, Q3, Q4 patterns)\")\n",
    "print(\"  • Validation: Q1 2023 (same season as prediction target)\")\n",
    "print(\"  • Model: Random Forest with hyperparameter tuning\")\n",
    "print(f\"  • Validation MAE: {results['val']['mae']:.3f} nurses\")\n",
    "print(f\"  • Validation R²: {results['val']['r2']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "print(f\"{'Ward':<18} {'Q1 2023':<10} {'Q1 2024':<10} {'Change':<10} {'Change %':<10} {'Uncertainty':<12} {'99% CI':<22} {'Action':<18} {'Priority'}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for _, row in q1_2024_predictions.iterrows():\n",
    "    print(\n",
    "        f\"{row['ward']:<18} \"\n",
    "        f\"{row['q1_2023_baseline']:>9.1f} \"\n",
    "        f\"{row['q1_2024_predicted']:>9.1f} \"\n",
    "        f\"{row['change']:>+9.1f} \"\n",
    "        f\"{row['change_pct']:>+8.1f}% \"\n",
    "        f\"±{row['uncertainty']:<10.2f} \"\n",
    "        f\"({row['ci_lower']:.1f}, {row['ci_upper']:.1f})\".ljust(22) +\n",
    "        f\"{row['action']:<18} \"\n",
    "        f\"{row['priority']}\"\n",
    "    )\n",
    "\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Summary\n",
    "total_2023 = q1_2024_predictions['q1_2023_baseline'].sum()\n",
    "total_2024 = q1_2024_predictions['q1_2024_predicted'].sum()\n",
    "total_change = total_2024 - total_2023\n",
    "\n",
    "print(f\"{'TOTAL':<18} {total_2023:>9.1f} {total_2024:>9.1f} {total_change:>+9.1f} {(total_change/total_2023)*100:>+8.1f}%\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Financial impact\n",
    "daily_cost_change = total_change * Config.HOURLY_NURSE_COST * Config.SHIFT_HOURS\n",
    "quarterly_cost_change = daily_cost_change * Config.QUARTER_DAYS\n",
    "\n",
    "print(\"\\nFINANCIAL IMPACT ANALYSIS:\")\n",
    "print(f\"  Daily cost change: ${daily_cost_change:,.2f}\")\n",
    "print(f\"  Quarterly cost change (Q1 2024): ${quarterly_cost_change:,.2f}\")\n",
    "print(f\"  Annual cost impact (if sustained): ${quarterly_cost_change * 4:,.2f}\")\n",
    "\n",
    "print(\"\\nKEY INSIGHTS:\")\n",
    "high_priority = q1_2024_predictions[q1_2024_predictions['priority'] == 'HIGH']\n",
    "if len(high_priority) > 0:\n",
    "    print(f\"  • HIGH PRIORITY wards: {', '.join(high_priority['ward'].tolist())}\")\n",
    "    for _, ward_row in high_priority.iterrows():\n",
    "        print(f\"    - {ward_row['ward']}: {ward_row['action']} ({ward_row['change']:+.1f} nurses)\")\n",
    "else:\n",
    "    print(\"  • No high-priority staffing changes required\")\n",
    "\n",
    "print(f\"\\n  • Average uncertainty: ±{q1_2024_predictions['uncertainty'].mean():.2f} nurses per ward\")\n",
    "print(f\"  • Expected Q1 2024 total: {total_2024:.1f} nurses/day ({total_change:+.1f} vs Q1 2023)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "# Save predictions\n",
    "predictions_file = f\"{Config.OUTPUT_DIR}/q1_2024_predictions.csv\"\n",
    "q1_2024_predictions.to_csv(predictions_file, index=False)\n",
    "logger.info(f\"Predictions saved to {predictions_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Q1 2024 predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ward comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(q1_2024_predictions))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, q1_2024_predictions['q1_2023_baseline'], width, \n",
    "        label='Q1 2023 Baseline', color='lightblue', alpha=0.8)\n",
    "ax1.bar(x + width/2, q1_2024_predictions['q1_2024_predicted'], width, \n",
    "        label='Q1 2024 Prediction', color='steelblue', alpha=0.8)\n",
    "\n",
    "# Error bars for uncertainty\n",
    "ax1.errorbar(x + width/2, q1_2024_predictions['q1_2024_predicted'], \n",
    "             yerr=q1_2024_predictions['uncertainty'], fmt='none', \n",
    "             color='black', capsize=5, alpha=0.6, label='Uncertainty (±1σ)')\n",
    "\n",
    "ax1.set_xlabel('Ward', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Average Nurses per Shift', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Q1 2024 Staffing Predictions by Ward', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(q1_2024_predictions['ward'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Change analysis\n",
    "ax2 = axes[1]\n",
    "colors = ['red' if x < 0 else 'green' for x in q1_2024_predictions['change']]\n",
    "bars = ax2.barh(q1_2024_predictions['ward'], q1_2024_predictions['change'], \n",
    "                color=colors, alpha=0.7)\n",
    "\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "ax2.set_xlabel('Change in Nurses (Q1 2024 vs Q1 2023)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Ward', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Staffing Change Requirements', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (ward, change) in enumerate(zip(q1_2024_predictions['ward'], q1_2024_predictions['change'])):\n",
    "    ax2.text(change + 0.1 if change > 0 else change - 0.1, i, \n",
    "             f\"{change:+.1f}\", va='center', ha='left' if change > 0 else 'right',\n",
    "             fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{Config.OUTPUT_DIR}/q1_2024_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"Q1 2024 predictions visualization saved to {Config.OUTPUT_DIR}/q1_2024_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendations and Action Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\" \"*35 + \"EXECUTIVE RECOMMENDATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n1. IMMEDIATE ACTIONS (Next 30 days):\")\n",
    "high_priority = q1_2024_predictions[q1_2024_predictions['priority'] == 'HIGH']\n",
    "if len(high_priority) > 0:\n",
    "    for _, ward in high_priority.iterrows():\n",
    "        print(f\"\\n   {ward['ward']}:\")\n",
    "        print(f\"     • Current Q1 baseline: {ward['q1_2023_baseline']:.1f} nurses/shift\")\n",
    "        print(f\"     • Q1 2024 requirement: {ward['q1_2024_predicted']:.1f} nurses/shift\")\n",
    "        print(f\"     • Action: {ward['action']} ({ward['change']:+.1f} nurses)\")\n",
    "        print(f\"     • Budget impact: ${abs(ward['change']) * Config.HOURLY_NURSE_COST * Config.SHIFT_HOURS * Config.QUARTER_DAYS:,.0f} quarterly\")\n",
    "else:\n",
    "    print(\"   • No immediate high-priority actions required\")\n",
    "    print(\"   • Continue monitoring current staffing levels\")\n",
    "\n",
    "print(\"\\n2. MEDIUM-TERM ACTIONS (30-90 days):\")\n",
    "medium_priority = q1_2024_predictions[q1_2024_predictions['priority'] == 'MEDIUM']\n",
    "if len(medium_priority) > 0:\n",
    "    for _, ward in medium_priority.iterrows():\n",
    "        print(f\"   • {ward['ward']}: {ward['action']} ({ward['change']:+.1f} nurses)\")\n",
    "else:\n",
    "    print(\"   • No medium-priority adjustments needed\")\n",
    "\n",
    "print(\"\\n3. OPERATIONAL IMPROVEMENTS:\")\n",
    "print(f\"   • Model Performance: {results['val']['r2']*100:.1f}% accuracy on seasonal validation\")\n",
    "print(f\"   • Expected Prediction Error: ±{results['val']['mae']:.2f} nurses per shift\")\n",
    "print(\"   • Recommendation: Retrain model quarterly with new data\")\n",
    "print(\"   • Implement real-time monitoring dashboard for staffing vs predictions\")\n",
    "print(\"   • Review and adjust monthly based on actual vs predicted staffing needs\")\n",
    "\n",
    "print(\"\\n4. RISK MITIGATION:\")\n",
    "print(\"   • Seasonal patterns show Q1 is typically more challenging than Q4\")\n",
    "print(\"   • February historically shows highest staffing shortfalls\")\n",
    "print(\"   • Prepare contingency staffing plans for predicted high-demand periods\")\n",
    "print(f\"   • Average uncertainty of ±{q1_2024_predictions['uncertainty'].mean():.2f} nurses suggests need for flexible staffing pool\")\n",
    "\n",
    "print(\"\\n5. FINANCIAL PLANNING:\")\n",
    "print(f\"   • Total Q1 2024 staffing requirement: {total_2024:.1f} nurses/day\")\n",
    "print(f\"   • Change from Q1 2023: {total_change:+.1f} nurses/day ({(total_change/total_2023)*100:+.1f}%)\")\n",
    "print(f\"   • Quarterly budget impact: ${quarterly_cost_change:,.2f}\")\n",
    "print(f\"   • Annual budget impact (if sustained): ${quarterly_cost_change * 4:,.2f}\")\n",
    "\n",
    "print(\"\\n6. MODEL MONITORING & MAINTENANCE:\")\n",
    "print(\"   • Track actual vs predicted staffing needs weekly\")\n",
    "print(\"   • Retrain model at end of Q1 2024 with new data\")\n",
    "print(\"   • Update feature engineering if new data patterns emerge\")\n",
    "print(\"   • Maintain 99% confidence intervals for conservative planning\")\n",
    "print(\"   • Review and refine business rules quarterly\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"\\nANALYSIS COMPLETE - Model ready for deployment and monitoring\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "summary = {\n",
    "    'analysis_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'model_type': 'Random Forest Regressor',\n",
    "    'validation_mae': results['val']['mae'],\n",
    "    'validation_r2': results['val']['r2'],\n",
    "    'validation_rmse': results['val']['rmse'],\n",
    "    'total_features': len(feature_cols),\n",
    "    'training_samples': len(X_train),\n",
    "    'validation_samples': len(X_val),\n",
    "    'q1_2023_total': total_2023,\n",
    "    'q1_2024_predicted': total_2024,\n",
    "    'total_change': total_change,\n",
    "    'quarterly_cost_impact': quarterly_cost_change,\n",
    "    'model_path': model_path,\n",
    "    'predictions_file': predictions_file\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_file = f\"{Config.OUTPUT_DIR}/analysis_summary.json\"\n",
    "import json\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "logger.info(f\"Analysis summary saved to {summary_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*25 + \"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAnalysis Date: {summary['analysis_date']}\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  • Type: {summary['model_type']}\")\n",
    "print(f\"  • Validation MAE: {summary['validation_mae']:.3f} nurses\")\n",
    "print(f\"  • Validation R²: {summary['validation_r2']:.3f} ({summary['validation_r2']*100:.1f}% accuracy)\")\n",
    "print(f\"  • Features Used: {summary['total_features']}\")\n",
    "print(f\"\\nQ1 2024 Forecast:\")\n",
    "print(f\"  • Total Requirement: {summary['q1_2024_predicted']:.1f} nurses/day\")\n",
    "print(f\"  • Change from Q1 2023: {summary['total_change']:+.1f} nurses/day\")\n",
    "print(f\"  • Quarterly Cost Impact: ${summary['quarterly_cost_impact']:,.2f}\")\n",
    "print(f\"\\nOutputs:\")\n",
    "print(f\"  • Model: {summary['model_path']}\")\n",
    "print(f\"  • Predictions: {summary['predictions_file']}\")\n",
    "print(f\"  • Summary: {summary_file}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "logger.info(\"Nursing workforce analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
